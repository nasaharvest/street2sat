{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9i5fMaQkbg6y"
      },
      "source": [
        "# Approved Crop KMZ to CSV\n",
        "\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/nasaharvest/street2sat/blob/main/notebooks/CropKMZtoCSV.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>\n",
        "\n",
        "**Author**: Ivan Zvonkov\n",
        "\n",
        "**Last Modified**: Feb 24, 2025\n",
        "\n",
        "**Description**: Converts approved KMZ to csv (for upload to Google Earth Engine)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPYfNELocD6U",
        "outputId": "2ff5b5e5-f29d-4e9f-fde2-5abb1f1e5391"
      },
      "outputs": [],
      "source": [
        "from bs4 import BeautifulSoup\n",
        "from google.colab import drive\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "\n",
        "import json\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "import zipfile\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tkr5nA9aqmTu"
      },
      "source": [
        "## 1. Convert each KMZ into a CSV file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ozKxISN3g5Ti",
        "outputId": "fb4d44ce-8a02-4f50-d53a-ef8104ef2c1f"
      },
      "outputs": [],
      "source": [
        "SRC_KMZ_FOLDER = \"/content/drive/MyDrive/SatLabel Squad/Kenya/Reviewed 2025-02-24 (KMZ)\"\n",
        "!ls \"{SRC_KMZ_FOLDER}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVDb7Vg3W4So"
      },
      "outputs": [],
      "source": [
        "SRC_KMZ_FILES = list(Path(SRC_KMZ_FOLDER).glob(\"*.kmz\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rU-CdpFBuRjt"
      },
      "outputs": [],
      "source": [
        "def get_points_from_kmz(kmz_file_path):\n",
        "    with zipfile.ZipFile(kmz_file_path, 'r') as kmz:\n",
        "        kml_filename = [name for name in kmz.namelist() if name.endswith('.kml')][0]\n",
        "        kml_data = kmz.read(kml_filename)\n",
        "\n",
        "    # Convert KMZ file to KMZ points list\n",
        "    namespace = {'kml': 'http://www.opengis.net/kml/2.2'}\n",
        "    kmz_points = []\n",
        "\n",
        "    root = ET.fromstring(kml_data)\n",
        "    for placemark in root.findall('.//kml:Placemark', namespace):\n",
        "        kmz_element = {}\n",
        "        for child in placemark.iter():\n",
        "            key = child.tag.replace('{http://www.opengis.net/kml/2.2}', '')\n",
        "            kmz_element[key] = child.text\n",
        "\n",
        "        kmz_points.append(kmz_element)\n",
        "\n",
        "    return kmz_points\n",
        "\n",
        "def kmz_points_to_dataframe(kmz_points):\n",
        "    points = []\n",
        "\n",
        "    for kmz_point in kmz_points:\n",
        "\n",
        "        row = {}\n",
        "\n",
        "        soup = BeautifulSoup(kmz_point[\"description\"], 'html.parser')\n",
        "        row[\"capture_info\"] = soup.find_all('h2')[0].text\n",
        "        row[\"capture_time\"] = soup.find_all('p')[0].text.split(\": \")[1]\n",
        "        row[\"image_url\"] = soup.find('a')['href']\n",
        "\n",
        "        # Driving direction details\n",
        "        direction_data = soup.find_all('h2')[2].next_siblings\n",
        "        direction_data = [item for item in direction_data if item.name == 'p']\n",
        "\n",
        "        row[\"driving_northing\"] = float(direction_data[0].text.split(\": \")[1])\n",
        "        row[\"driving_easting\"] = float(direction_data[1].text.split(\": \")[1])\n",
        "        row[\"is_right_hand_drive\"] = direction_data[2].text.split(\": \")[1] == 'True'\n",
        "\n",
        "        # Location details\n",
        "        location_data = soup.find_all('h2')[1].next_siblings\n",
        "        location_data = [item for item in location_data if item.name == 'p']\n",
        "        row[\"adm1\"] = location_data[0].text.split(\": \")[1]\n",
        "        row[\"adm2\"] = location_data[1].text.split(\": \")[1]\n",
        "\n",
        "        def lat_lon_parse(lat_lon_str):\n",
        "            lat_lon = lat_lon_str.text.split(\": \")[1] \\\n",
        "                .replace('(', '').replace(')', '') \\\n",
        "                .replace('[', '').replace(']', '')\n",
        "            return json.loads(f\"[{lat_lon}]\")\n",
        "\n",
        "        road_lat_lon = lat_lon_parse(location_data[2])\n",
        "        field_lat_lon = lat_lon_parse(location_data[3])\n",
        "\n",
        "        crop_type = kmz_point[\"name\"].strip().lower().replace(\"\\u200b\", \"\")\n",
        "        crop_point = {\n",
        "            \"latitude\": field_lat_lon[0],\n",
        "            \"longitude\": field_lat_lon[1],\n",
        "            \"is_crop\": 1,\n",
        "            \"is_maize\": int(crop_type == \"maize\"),\n",
        "            \"crop_type\": crop_type,\n",
        "\n",
        "            **row,\n",
        "        }\n",
        "\n",
        "        non_crop_point = {\n",
        "            \"latitude\": road_lat_lon[0],\n",
        "            \"longitude\": road_lat_lon[1],\n",
        "            \"is_crop\": 0,\n",
        "            \"is_maize\": 0,\n",
        "            \"crop_type\": \"\",\n",
        "            **row,\n",
        "        }\n",
        "\n",
        "        points.append(crop_point)\n",
        "        points.append(non_crop_point)\n",
        "\n",
        "    df = pd.DataFrame(points)\n",
        "    df[\"gcloud_folder\"] = df[\"image_url\"].str.extract(r'street2sat-uploaded/([^/]+/[^/]+)')\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfPTfX5jumZ4",
        "outputId": "b702ac0c-f69c-4676-cfd5-1989e47d33c9"
      },
      "outputs": [],
      "source": [
        "dfs = []\n",
        "for kmz_file_path in tqdm(SRC_KMZ_FILES):\n",
        "    kmz_points = get_points_from_kmz(kmz_file_path)\n",
        "    df = kmz_points_to_dataframe(kmz_points)\n",
        "    dfs.append(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gC_QHgCqr-1"
      },
      "source": [
        "## 2. Merge CSV files into single file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u1urg44Vutp9"
      },
      "outputs": [],
      "source": [
        "df = pd.concat(dfs, ignore_index=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "r9_eFiXvuzg4",
        "outputId": "38d485a4-2fbb-4023-eed2-8fbe672e2719"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "X6M-l4uprs4a",
        "outputId": "2113496d-57bb-46b3-c1df-fa076556f185"
      },
      "outputs": [],
      "source": [
        "df[df[\"is_crop\"] == 1][\"gcloud_folder\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8VwkSHnuzScJ"
      },
      "outputs": [],
      "source": [
        "df_2021 = df[df[\"gcloud_folder\"].str.contains(\"2021\")]\n",
        "df_2022 = df[df[\"gcloud_folder\"].str.contains(\"2022\")]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "4CtusCN5wYEd",
        "outputId": "5b12b67d-c620-4add-d7b8-81c0b1901a11"
      },
      "outputs": [],
      "source": [
        "df_2021[[\"is_crop\", \"crop_type\"]].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 115
        },
        "id": "D9w4w_I6zhtX",
        "outputId": "b3473a55-b4ed-4a40-9617-9a292c173477"
      },
      "outputs": [],
      "source": [
        "df_2022[[\"is_crop\", \"crop_type\"]].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_n9cuNErxslV"
      },
      "outputs": [],
      "source": [
        "df_2021.to_csv(f\"/content/drive/MyDrive/Helmets/Kenya_2021_batch202502.csv\", index=False)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
